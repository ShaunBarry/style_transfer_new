{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import librosa\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "from IPython.core.display import display\n",
    "from tensorflow.python.client import device_lib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 22050\n",
    "N_DFT = 2048\n",
    "HOP_LEN = N_DFT // 4\n",
    "\n",
    "N_FILTERS_STFT = 4096\n",
    "kernel_stft = [1,11]\n",
    "num_stft_layers = 1\n",
    "\n",
    "if num_stft_layers == 1:\n",
    "    padding_stft = \"VALID\"\n",
    "else:\n",
    "    padding_stft = \"SAME\"\n",
    "    \n",
    "initializer = tf.keras.initializers.lecun_normal()\n",
    "\n",
    "loss_dict_coeffs = {'style':{'stft':10.0},\n",
    "                    'content':{'stft':1.0}}\n",
    "maxiter = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "def normalize(y):\n",
    "    return y/np.abs(y).max()\n",
    "\n",
    "def load_audio(fn, sr=SR, times=[0,10]):\n",
    "    return normalize(librosa.load(fn, sr=sr)[0].astype(np.float32)[sr*times[0]:sr*times[1]])\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    devices = [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "    if devices == []:\n",
    "        return ['/cpu:0']\n",
    "    else:\n",
    "        return devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_fn = 'examples/usa.wav'\n",
    "style_times = [0,10]\n",
    "content_fn = 'examples/imperial.wav'\n",
    "content_times = [11,21]\n",
    "\n",
    "x_content = load_audio(content_fn, SR, content_times)\n",
    "x_style = load_audio(style_fn, SR, style_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     14
    ]
   },
   "outputs": [],
   "source": [
    "def elu(x, alpha=1.):\n",
    "    \"\"\"Exponential linear unit.\n",
    "    # Arguments\n",
    "        x: A tenor or variable to compute the activation function for.\n",
    "        alpha: A scalar, slope of positive section.\n",
    "    # Returns\n",
    "        A tensor.\n",
    "    \"\"\"\n",
    "    res = tf.nn.elu(x)\n",
    "    if alpha == 1:\n",
    "        return res\n",
    "    else:\n",
    "        return tf.where(x > 0, res, alpha * res)\n",
    "\n",
    "def selu(x):\n",
    "    \"\"\"Scaled Exponential Linear Unit. (Klambauer et al., 2017)\n",
    "    # Arguments\n",
    "        x: A tensor or variable to compute the activation function for.\n",
    "    # References\n",
    "        - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n",
    "    \"\"\"\n",
    "    alpha = 1.6732632423543772848170429916717\n",
    "    scale = 1.0507009873554804934193349852946\n",
    "    return scale * elu(x, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     22,
     37
    ]
   },
   "outputs": [],
   "source": [
    "def conv_complex(x, \n",
    "             n_filters=N_FILTERS_STFT, \n",
    "             kernel_stft=kernel_stft, \n",
    "             padding=padding_stft,\n",
    "             name=\"\",\n",
    "             reuse=False):\n",
    "    n_filters_in = x.get_shape.as_list()[-1]\n",
    "    x_real = x[:,:,:,:n_filters_in/2]\n",
    "    x_imag = x[:,:,:,n_filters_in/2:]\n",
    "    output_real_real = tf.contrib.layers.conv2d(inputs=x_real, num_outputs=n_filters, kernel_size=kernel_stft, stride=1, padding=padding, \\\n",
    "                                        reuse=reuse, activation_fn=None, weights_initializer=initializer, scope=name+\"_real\")\n",
    "    output_imag_imag = tf.contrib.layers.conv2d(inputs=x_imag, num_outputs=n_filters, kernel_size=kernel_stft, stride=1, padding=padding, \\\n",
    "                                        reuse=reuse, activation_fn=None, weights_initializer=initializer, scope=name+\"_imag\")\n",
    "    output_real_imag = tf.contrib.layers.conv2d(inputs=x_real, num_outputs=n_filters, kernel_size=kernel_stft, stride=1, padding=padding, \\\n",
    "                                        reuse=True, activation_fn=None, weights_initializer=initializer, scope=name+\"_imag\")\n",
    "    output_imag_real = tf.contrib.layers.conv2d(inputs=x_imag, num_outputs=n_filters, kernel_size=kernel_stft, stride=1, padding=padding, \\\n",
    "                                        reuse=True, activation_fn=None, weights_initializer=initializer, scope=name+\"_real\")\n",
    "    \n",
    "    output_real = selu(output_real_real - output_imag_imag)\n",
    "    output_imag = selu(output_real_imag + output_imag_real)\n",
    "    return tf.concat([output_real, output_imag], axis=-1)\n",
    "\n",
    "def stft_net(x, \n",
    "             n_filters=N_FILTERS_STFT, \n",
    "             kernel_stft=kernel_stft, \n",
    "             padding=padding_stft,\n",
    "             num_layers=1,\n",
    "             reuse=False):\n",
    "    \n",
    "    with tf.variable_scope(\"stft_net\"):\n",
    "        x_reshaped = x[tf.newaxis, tf.newaxis, :, :]\n",
    "        layers_list = [x_reshaped]\n",
    "        for i in range(num_layers):\n",
    "            layers_list += [tf.contrib.layers.conv2d(inputs=layers_list[-1], num_outputs=n_filters, kernel_size=kernel_stft, stride=1, padding=padding, \\\n",
    "                                        reuse=reuse, activation_fn=selu, weights_initializer=initializer, scope=\"stft_conv\"+str(i))]\n",
    "        return layers_list[1:]\n",
    "    \n",
    "def stft_net_complex(x, \n",
    "             n_filters=N_FILTERS_STFT, \n",
    "             kernel_stft=kernel_stft, \n",
    "             padding=padding_stft,\n",
    "             num_layers=1,\n",
    "             reuse=False):\n",
    "    with tf.variable_scope(\"stft_net\"):\n",
    "        x_reshaped = x[tf.newaxis, tf.newaxis, :, :]\n",
    "        x_real_version = tf.concat([tf.real(x), tf.imag(x)], axis=-1)\n",
    "        layers_list = [x_real_version]\n",
    "        for i in range(num_layers):\n",
    "            layers_list += [conv_complex(layers_list[-1], n_filters=n_filters,  kernel_stft=kernel_stft, \n",
    "             padding=padding, name=\"stft_conv\"+str(i), reuse=reuse)]\n",
    "        return layers_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     34
    ]
   },
   "outputs": [],
   "source": [
    "def compute_style_loss(net, style_net):\n",
    "    if type(net) == list:\n",
    "        style_loss = 0\n",
    "        gram = []\n",
    "        s_gram = []\n",
    "        for (n, sn) in zip(net, style_net):\n",
    "            _, height, width, number = map(lambda i: i.value, n.get_shape())\n",
    "            _, height_style, width_style, number = map(lambda i: i.value, sn.get_shape())\n",
    "            \n",
    "            factor = height*width\n",
    "            style_factor = height_style*width_style\n",
    "            \n",
    "            feats_style = tf.reshape(sn, (-1, number))\n",
    "            feats = tf.reshape(n, (-1, number))\n",
    "            \n",
    "            gram += [tf.matmul(tf.transpose(feats), feats)/factor]\n",
    "            s_gram += [tf.matmul(tf.transpose(feats_style), feats_style)/style_factor]\n",
    "            style_loss += 2 * tf.nn.l2_loss(gram[-1] - s_gram[-1])\n",
    "    else:\n",
    "        _, height, width, number = map(lambda i: i.value, net.get_shape())\n",
    "        _, height_style, width_style, number = map(lambda i: i.value, style_net.get_shape())\n",
    "        \n",
    "        factor = height*width\n",
    "        style_factor = height_style*width_style\n",
    "        \n",
    "        feats = tf.reshape(net, (-1, number))\n",
    "        feats_style = tf.reshape(style_net, (-1, number))\n",
    "\n",
    "        gram = tf.matmul(tf.transpose(feats), feats)/factor\n",
    "        style_gram = tf.matmul(tf.transpose(feats_style), feats_style)/style_factor\n",
    "        style_loss = loss_fn(gram, style_gram, \"style\")\n",
    "\n",
    "    return style_loss\n",
    "\n",
    "def compute_style_loss_complex(net, style_net):\n",
    "    if type(net) != list:\n",
    "        net = [net]\n",
    "        style_net = [style_net]\n",
    "    style_loss = 0\n",
    "    gram = []\n",
    "    s_gram = []\n",
    "    for (n, sn) in zip(net, style_net):\n",
    "\n",
    "        _, height, width, number = map(lambda i: i.value, n.get_shape())\n",
    "        _, height_style, width_style, number = map(lambda i: i.value, sn.get_shape())\n",
    "\n",
    "        n = tf.complex(n[:,:,:,:number//2],n[:,:,:,number//2:])\n",
    "        sn = tf.complex(n[:,:,:,:number//2],n[:,:,:,number//2:])\n",
    "\n",
    "        factor = height*width\n",
    "        style_factor = height_style*width_style\n",
    "\n",
    "        feats_style = tf.reshape(sn, (-1, number//2))\n",
    "        feats = tf.reshape(n, (-1, number//2))\n",
    "\n",
    "        gram += [tf.matmul(tf.transpose(feats, conjugate=True), feats)/factor]\n",
    "        s_gram += [tf.matmul(tf.transpose(feats_style, conjugate=True), feats_style)/style_factor]\n",
    "        style_loss += 2 * tf.nn.l2_loss(tf.abs(gram[-1] - s_gram[-1]))\n",
    "\n",
    "    return style_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Counter(object):\n",
    "    def __init__(self):\n",
    "        self.iters = 0\n",
    "\n",
    "    def __call__(self, x):\n",
    "        #print type(x), x.shape, self.prev_x.shape\n",
    "\n",
    "        sys.stdout.write('\\riters: {}'.format(self.iters))\n",
    "        sys.stdout.flush()\n",
    "        self.iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427, 1025)\n",
      "Gradient norms: {'content': {'stft': 98969.8}, 'style': {'stft': 64720.223}}\n",
      "iters: 6271"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    \n",
    "    config = tf.ConfigProto(allow_soft_placement = True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    device = get_available_devices()[0]\n",
    "    \n",
    "    with g.device(device):\n",
    "        x_content_time = tf.constant(x_content)\n",
    "        x_style_time = tf.constant(x_style)\n",
    "        x_target_time = tf.Variable(1e-3*np.random.randn(x_content.shape[0]).astype(np.float32))\n",
    "\n",
    "        # get STFTs\n",
    "        x_content_stft = tf.log1p(tf.abs(tf.contrib.signal.stft(x_content_time, N_DFT, HOP_LEN)))\n",
    "        x_style_stft = tf.log1p(tf.abs(tf.contrib.signal.stft(x_style_time, N_DFT, HOP_LEN)))\n",
    "        x_target_stft = tf.log1p(tf.abs(tf.contrib.signal.stft(x_target_time, N_DFT, HOP_LEN)))\n",
    "        print(x_content_stft.get_shape())\n",
    "        \n",
    "        # get networks\n",
    "        X_content_stftnet = stft_net(x_content_stft)\n",
    "        X_style_stftnet = stft_net(x_style_stft, reuse=True)\n",
    "        X_target_stftnet = stft_net(x_target_stft, reuse=True)\n",
    "        \n",
    "        \n",
    "        losses = {'style':{},'content':{}}\n",
    "        losses['style']['stft'] = compute_style_loss(X_style_stftnet, X_target_stftnet)\n",
    "        losses['content']['stft'] = tf.nn.l2_loss(X_content_stftnet[-1] - X_target_stftnet[-1])\n",
    "        \n",
    "        grads_norm = {'style':{},'content':{}}\n",
    "        for s in ['style','content']:\n",
    "            for l in losses[s].keys():\n",
    "                grads_norm[s][l] = tf.norm(tf.gradients([losses[s][l]], x_target_time)[0])\n",
    "        \n",
    "        grads_norms_evaled = {'style':{},'content':{}}\n",
    "        with tf.Session(config=config) as sess:\n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "\n",
    "            for s in ['content','style']:\n",
    "                for l in losses[s].keys():\n",
    "                    grads_norms_evaled[s][l] = sess.run(grads_norm[s][l])\n",
    "                    if not ((s == 'content') and (l == 'stft')):\n",
    "                        losses[s][l] = losses[s][l]*(grads_norms_evaled['content']['stft']/grads_norms_evaled[s][l])\n",
    "            \n",
    "            loss = 0.0\n",
    "            for s in ['content','style']:\n",
    "                for l in losses[s].keys():\n",
    "                    loss += loss_dict_coeffs[s][l]*losses[s][l]\n",
    "            \n",
    "            print('Gradient norms:', grads_norms_evaled)\n",
    "            \n",
    "            opt = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "                      loss, var_list=[x_target_time], method='L-BFGS-B', options={'maxiter': maxiter})\n",
    "            \n",
    "            counter = Counter()\n",
    "            opt.minimize(sess, step_callback=counter)                \n",
    "            x_target_time_final = normalize(x_target_time.eval())\n",
    "            display(Audio(x_target_time_final, rate=SR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    \n",
    "    config = tf.ConfigProto(allow_soft_placement = True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    device = get_available_devices()[0]\n",
    "    \n",
    "    with g.device(device):\n",
    "        x_content_time = tf.constant(x_content)\n",
    "        x_style_time = tf.constant(x_style)\n",
    "        x_target_time = tf.Variable(1e-3*np.random.randn(x_content.shape[0]).astype(np.float32))\n",
    "\n",
    "        # get STFTs\n",
    "        x_content_stft = tf.contrib.signal.stft(x_content_time, N_DFT, HOP_LEN)\n",
    "        x_style_stft = tf.contrib.signal.stft(x_style_time, N_DFT, HOP_LEN)\n",
    "        x_target_stft = tf.contrib.signal.stft(x_target_time, N_DFT, HOP_LEN)\n",
    "        print(x_content_stft.get_shape())\n",
    "        \n",
    "        # get networks\n",
    "        x_content_stft = tf.concat([tf.real(x_content_stft), tf.imag(x_content_stft)], axis=-1)\n",
    "        x_style_stft = tf.concat([tf.real(x_style_stft), tf.imag(x_style_stft)], axis=-1)\n",
    "        x_target_stft = tf.concat([tf.real(x_target_stft), tf.imag(x_target_stft)], axis=-1)\n",
    "        \n",
    "        X_content_stftnet = stft_net_complex(x_content_stft)\n",
    "        X_style_stftnet = stft_net_complex(x_style_stft, reuse=True)\n",
    "        X_target_stftnet = stft_net_complex(x_target_stft, reuse=True)\n",
    "        \n",
    "        losses = {'style':{},'content':{}}\n",
    "        losses['style']['stft'] = compute_style_loss_complex(X_style_stftnet, X_target_stftnet)\n",
    "        losses['content']['stft'] = tf.nn.l2_loss(tf.abs(X_content_stftnet[-1] - X_target_stftnet[-1]))\n",
    "        \n",
    "        grads_norm = {'style':{},'content':{}}\n",
    "        for s in ['style','content']:\n",
    "            for l in losses[s].keys():\n",
    "                grads_norm[s][l] = tf.norm(tf.gradients([losses[s][l]], x_target_time)[0])\n",
    "        \n",
    "        grads_norms_evaled = {'style':{},'content':{}}\n",
    "        with tf.Session(config=config) as sess:\n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "\n",
    "            for s in ['content','style']:\n",
    "                for l in losses[s].keys():\n",
    "                    grads_norms_evaled[s][l] = sess.run(grads_norm[s][l])\n",
    "                    if not ((s == 'content') and (l == 'stft')):\n",
    "                        losses[s][l] = losses[s][l]*(grads_norms_evaled['content']['stft']/grads_norms_evaled[s][l])\n",
    "            \n",
    "            loss = 0.0\n",
    "            for s in ['content','style']:\n",
    "                for l in losses[s].keys():\n",
    "                    loss += loss_dict_coeffs[s][l]*losses[s][l]\n",
    "            \n",
    "            print('Gradient norms:', grads_norms_evaled)\n",
    "            \n",
    "            opt = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "                      loss, var_list=[x_target_time], method='L-BFGS-B', options={'maxiter': maxiter})\n",
    "            \n",
    "            counter = Counter()\n",
    "            opt.minimize(sess, step_callback=counter)                \n",
    "            x_target_time_final = normalize(x_target_time.eval())\n",
    "            display(Audio(x_target_time_final, rate=SR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
